ğŸ§¾ Defensive Publication: Visual Scene Language (VSL)

Author: Maxim Zhadobin
Publication Date: 28.05.2025
Version: v0.1

â¸»

ğŸ“˜ Invention Title

Method for Representing and Editing Visual Scenes for Language Models via a Structured Format: Visual Scene Language (VSL)

â¸»

ğŸ“Œ Application Domains
	â€¢	Artificial Intelligence and Large Language Models (LLMs)
	â€¢	Image generation and editing
	â€¢	UX/UI design
	â€¢	Architecture, Engineering, and Construction (AEC)
	â€¢	2D/3D modeling, AR/VR

â¸»

ğŸ§  Abstract

A method is proposed for describing visual scenes in a machine-readable format interpretable by language models (LLMs). The format is a structured JSON schema containing:
	â€¢	canvas parameters (dimensions, measurement units, background),
	â€¢	a list of objects (type, size, coordinates, anchor points),
	â€¢	optional styles and object relationships.

An LLM can use this structure:
	â€¢	to understand the image as a meaningful scene,
	â€¢	to edit the scene based on textual commands,
	â€¢	to generate a new scene,
	â€¢	to reconstruct an image from the JSON.

â¸»

ğŸ”„ Technological Workflow
	1.	An image is converted into a JSON-based scene structure (VSL).
	2.	The LLM interprets and modifies the JSON in response to a text prompt.
	3.	The modified JSON is rendered into a new image.
	4.	The cycle may repeat iteratively.

â¸»

ğŸ§© Distinctive Features
	â€¢	Unlike generative models (DALLÂ·E, Midjourney), this method separates the semantic structure of the scene from its visual rendering.
	â€¢	Unlike scene graphs in computer graphics, VSL is optimized for language models and semantic processing.
	â€¢	The method does not require a visual interface â€” interaction occurs through structure and natural language commands.

â¸»

ğŸ’¡ Example Applications
	â€¢	Editing user interfaces, slides, and illustrations without a visual editor.
	â€¢	Generating AR/VR scenes from textual scenarios.
	â€¢	Interactive assistants working with visual objects.
	â€¢	Robotics: LLM perceives the environment through VSL and gives structured commands.
	â€¢	Architectural and engineering design: users describe a building or structure via text; the LLM generates a corresponding VSL structure. A renderer builds a 2D/3D model from it. Edits are made via natural language and reflected in the scene. The system can also validate design choices against regulatory standards.

â¸»

ğŸ“œ Legal Status

This document is published with the intent to prevent patent claims by third parties. The author waives exclusive patent rights in favor of public use but formally asserts authorship, concept origin, and publication date.

â¸»

ğŸ“ Attachments (to be included in GitHub repository)
	â€¢	vsl_scene_example.json: example scene with a red rectangle
	â€¢	llm_prompts_examples.md: prompt examples for modifying the scene
	â€¢	vsl_to_image.py: Python script to visualize the JSON scene
	â€¢	vsl_editor_mockup.ipynb: (optional) Jupyter Notebook mock editor
	â€¢	Extended format specs: styles, materials, animation, 3D coordinates, behavioral logic

â¸»

ğŸ”– License

Creative Commons Attribution 4.0 International (CC BY 4.0)

â¸»

â€œVisual Scene Language is not just a way to describe an image â€” it is a language for spatial thinking by artificial intelligence.â€
